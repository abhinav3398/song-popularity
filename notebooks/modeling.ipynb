{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "putting it all togather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76d55aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T19:11:23.964432Z",
     "iopub.status.busy": "2022-01-23T19:11:23.963235Z",
     "iopub.status.idle": "2022-01-23T19:11:25.232269Z",
     "shell.execute_reply": "2022-01-23T19:11:25.231514Z",
     "shell.execute_reply.started": "2022-01-23T18:57:12.092847Z"
    },
    "id": "jFUNjl9DDQ5W",
    "papermill": {
     "duration": 1.391481,
     "end_time": "2022-01-23T19:11:25.232471",
     "exception": false,
     "start_time": "2022-01-23T19:11:23.840990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#For the plots\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e89def",
   "metadata": {},
   "source": [
    "set random reed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01e7c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "# np.random.seed = random_state\n",
    "rng = np.random.default_rng(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e34ad074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T19:11:25.474732Z",
     "iopub.status.busy": "2022-01-23T19:11:25.474052Z",
     "iopub.status.idle": "2022-01-23T19:11:25.739303Z",
     "shell.execute_reply": "2022-01-23T19:11:25.738546Z",
     "shell.execute_reply.started": "2022-01-23T18:57:13.416134Z"
    },
    "id": "OeqxIfFuPDnq",
    "papermill": {
     "duration": 0.388166,
     "end_time": "2022-01-23T19:11:25.739456",
     "exception": false,
     "start_time": "2022-01-23T19:11:25.351290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/processed/train.csv')\n",
    "train.drop(['id'], inplace=True, axis=1)\n",
    "\n",
    "test = pd.read_csv('../data/processed/test.csv')\n",
    "test.drop(['id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "201eb040",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_y = 'song_popularity'\n",
    "\n",
    "X = train.copy()\n",
    "y = X.pop(col_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ca7f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = X.nunique() < 15\n",
    "categorical_cols = X.columns[mask]\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8bdeb06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   song_duration_ms  35899 non-null  float64\n",
      " 1   acousticness      36008 non-null  float64\n",
      " 2   danceability      35974 non-null  float64\n",
      " 3   energy            36025 non-null  float64\n",
      " 4   instrumentalness  36015 non-null  float64\n",
      " 5   liveness          35914 non-null  float64\n",
      " 6   loudness          36043 non-null  float64\n",
      " 7   speechiness       40000 non-null  float64\n",
      " 8   tempo             40000 non-null  float64\n",
      " 9   audio_valence     40000 non-null  float64\n",
      " 10  key_0             40000 non-null  uint8  \n",
      " 11  key_1             40000 non-null  uint8  \n",
      " 12  key_2             40000 non-null  uint8  \n",
      " 13  key_3             40000 non-null  uint8  \n",
      " 14  key_4             40000 non-null  uint8  \n",
      " 15  key_5             40000 non-null  uint8  \n",
      " 16  key_6             40000 non-null  uint8  \n",
      " 17  key_7             40000 non-null  uint8  \n",
      " 18  key_8             40000 non-null  uint8  \n",
      " 19  key_9             40000 non-null  uint8  \n",
      " 20  key_10            40000 non-null  uint8  \n",
      " 21  key_11            40000 non-null  uint8  \n",
      " 22  audio_mode_0      40000 non-null  uint8  \n",
      " 23  audio_mode_1      40000 non-null  uint8  \n",
      " 24  time_signature_2  40000 non-null  uint8  \n",
      " 25  time_signature_3  40000 non-null  uint8  \n",
      " 26  time_signature_4  40000 non-null  uint8  \n",
      " 27  time_signature_5  40000 non-null  uint8  \n",
      "dtypes: float64(10), uint8(18)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "# convert audio_mode, key & time_signature column values to categorical\n",
    "X['key'] = X['key'].astype( \"Int64\")\n",
    "X[categorical_cols] = X[categorical_cols].astype('category')\n",
    "X = pd.get_dummies(X)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in train, validation & test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=random_state, stratify=y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32000, 28), (25600, 28), (6400, 28), (8000, 28))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modeling & pre/post-processing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.experimental import enable_iterative_imputer, enable_halving_search_cv\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, MissingIndicator, IterativeImputer, MissingIndicator\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer, MinMaxScaler, PowerTransformer, RobustScaler, power_transform, minmax_scale\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV, HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc, classification_report\n",
    "\n",
    "# import classifier models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV, Lasso, LassoCV, ElasticNet, ElasticNetCV, LogisticRegressionCV, SGDClassifier, SGDRegressor, Ridge, LassoLarsCV, LassoLars, BayesianRidge, RidgeCV\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "sys.path.append(\"kuma_utils/\")\n",
    "from kuma_utils.preprocessing.imputer import LGBMImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns used for inverse sigmoid transformation\n",
    "from sklearn.preprocessing import MinMaxScaler, minmax_scale, PowerTransformer, FunctionTransformer\n",
    "# from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "col_sig = [\n",
    "    'acousticness',\n",
    "    'danceability',\n",
    "    'energy',\n",
    "    'instrumentalness',\n",
    "    'liveness',\n",
    "    'speechiness',\n",
    "    'audio_valence',\n",
    "]\n",
    "\n",
    "col_pow = [\n",
    "    'song_duration_ms',\n",
    "    'tempo',\n",
    "]\n",
    "\n",
    "# make a custom transformer to transform the data\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PreProcessorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols, show_impute=False, inplace=False):\n",
    "        self.show_impute = show_impute\n",
    "        self.inplace = inplace\n",
    "        self.col_sig, self.col_pow, self.loudness = cols\n",
    "        self.cols = self.col_sig + self.col_pow\n",
    "        self.inv_sigmoid = FunctionTransformer(lambda x: np.log(x / (1-x)))\n",
    "        self.loudness_transformer = FunctionTransformer(lambda x: np.log1p(-x))\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "            \n",
    "        self.scaler = MinMaxScaler(feature_range=(0+1e-6, 1-1e-6)).fit(X[self.col_sig])\n",
    "        \n",
    "        X_tmp = X[self.col_sig+self.col_pow].copy()\n",
    "        X_tmp[self.col_sig] = self.scaler.transform(X_tmp[self.col_sig])\n",
    "        X_tmp[self.col_sig] = self.inv_sigmoid.fit_transform(X_tmp[self.col_sig])\n",
    "        \n",
    "        self.transformer = PowerTransformer().fit(X_tmp)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if not self.inplace:\n",
    "            X = X.copy()\n",
    "        \n",
    "        X[self.col_sig] = self.scaler.transform(X[self.col_sig])\n",
    "        X[self.col_sig] = self.inv_sigmoid.fit_transform(X[self.col_sig])\n",
    "    #    # Box-Cox transformation\n",
    "        X[self.col_sig+self.col_pow] = self.transformer.transform(X[self.col_sig+self.col_pow])\n",
    "        X[self.loudness] = self.loudness_transformer.fit_transform(X[self.loudness])\n",
    "        \n",
    "        if y is None:\n",
    "            return X\n",
    "        else:\n",
    "            return X, y\n",
    "\n",
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, outlier_remover, **kwrgs):\n",
    "        self.outlier_remover = outlier_remover(**kwrgs)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        y_hat = self.outlier_remover.fit_predict(X)\n",
    "        mask = y_hat != -1\n",
    "        \n",
    "        if y is None:\n",
    "            return X.iloc[mask, :]\n",
    "        else:\n",
    "            return X.iloc[mask, :], y[mask]\n",
    "\n",
    "class Imputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, imputer, **kwrgs):\n",
    "        self.add_indicator = kwrgs.get('add_indicator', False)\n",
    "        self.imputer = imputer(**kwrgs)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        col = X.columns\n",
    "        if self.add_indicator:\n",
    "            mask = X.isna().any(axis=0)\n",
    "            self.imputed_col_names = col.tolist()+[\"_\"+col+\"_imputed_\" for col in mask[mask].index]\n",
    "        else:\n",
    "            self.imputed_col_names = col\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        train_knnimp = self.imputer.fit_transform(X)\n",
    "        X = pd.DataFrame(train_knnimp, columns=self.imputed_col_names)\n",
    "        \n",
    "        if y is None:\n",
    "            return X\n",
    "        else:\n",
    "            return X, y\n",
    "\n",
    "\n",
    "imputer = Imputer(IterativeImputer, add_indicator=True, max_iter=10)\n",
    "transformer = PreProcessorTransformer([col_sig, col_pow, 'loudness'])\n",
    "outlier_remover = OutlierRemover(LocalOutlierFactor, n_neighbors=20, contamination=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed {color: black;background-color: white;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed pre{padding: 0;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-toggleable {background-color: white;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-estimator:hover {background-color: #d4ebff;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-item {z-index: 1;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-parallel-item:only-child::after {width: 0;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-2ba7c836-cc09-4f78-8c1b-058b7ec009ed\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"fb995ec7-0c74-4a65-88dd-1d40effb8a03\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"fb995ec7-0c74-4a65-88dd-1d40effb8a03\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('na-imputation',\n",
       "                 Imputer(imputer=IterativeImputer(add_indicator=True))),\n",
       "                ('transformation',\n",
       "                 PreProcessorTransformer(cols=['acousticness', 'danceability',\n",
       "                                               'energy', 'instrumentalness',\n",
       "                                               'liveness', 'speechiness',\n",
       "                                               'audio_valence',\n",
       "                                               'song_duration_ms', 'tempo'])),\n",
       "                ('outlier remover',\n",
       "                 OutlierRemover(outlier_remover=LocalOutlierFactor(contamination=0.02)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"69187b3c-18c2-43e4-9fc0-0e292bf47817\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"69187b3c-18c2-43e4-9fc0-0e292bf47817\">na-imputation: Imputer</label><div class=\"sk-toggleable__content\"><pre>Imputer(imputer=IterativeImputer(add_indicator=True))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d260e252-ef93-4448-a1c8-e1b753441045\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d260e252-ef93-4448-a1c8-e1b753441045\">IterativeImputer</label><div class=\"sk-toggleable__content\"><pre>IterativeImputer(add_indicator=True)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c82e3f2a-63cc-47a2-a4bd-10901c7733df\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c82e3f2a-63cc-47a2-a4bd-10901c7733df\">PreProcessorTransformer</label><div class=\"sk-toggleable__content\"><pre>PreProcessorTransformer(cols=['acousticness', 'danceability', 'energy',\n",
       "                              'instrumentalness', 'liveness', 'speechiness',\n",
       "                              'audio_valence', 'song_duration_ms', 'tempo'])</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b5a1d350-b61b-4287-9ab7-b78a1380d060\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b5a1d350-b61b-4287-9ab7-b78a1380d060\">outlier remover: OutlierRemover</label><div class=\"sk-toggleable__content\"><pre>OutlierRemover(outlier_remover=LocalOutlierFactor(contamination=0.02))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"44ab24ab-d657-44dd-a0cc-7dc2bf46ccda\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"44ab24ab-d657-44dd-a0cc-7dc2bf46ccda\">LocalOutlierFactor</label><div class=\"sk-toggleable__content\"><pre>LocalOutlierFactor(contamination=0.02)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('na-imputation',\n",
       "                 Imputer(imputer=IterativeImputer(add_indicator=True))),\n",
       "                ('transformation',\n",
       "                 PreProcessorTransformer(cols=['acousticness', 'danceability',\n",
       "                                               'energy', 'instrumentalness',\n",
       "                                               'liveness', 'speechiness',\n",
       "                                               'audio_valence',\n",
       "                                               'song_duration_ms', 'tempo'])),\n",
       "                ('outlier remover',\n",
       "                 OutlierRemover(outlier_remover=LocalOutlierFactor(contamination=0.02)))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor_pipe = Pipeline([\n",
    "    (\"na-imputation\", imputer),\n",
    "    (\"transformation\", transformer),\n",
    "    ('outlier remover', outlier_remover),\n",
    "])\n",
    "preprocessor_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_duration_ms</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>audio_valence</th>\n",
       "      <th>...</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "      <th>_song_duration_ms_imputed_</th>\n",
       "      <th>_acousticness_imputed_</th>\n",
       "      <th>_danceability_imputed_</th>\n",
       "      <th>_energy_imputed_</th>\n",
       "      <th>_instrumentalness_imputed_</th>\n",
       "      <th>_liveness_imputed_</th>\n",
       "      <th>_loudness_imputed_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.270568</td>\n",
       "      <td>-1.147494</td>\n",
       "      <td>0.528199</td>\n",
       "      <td>0.350624</td>\n",
       "      <td>-0.321015</td>\n",
       "      <td>0.802553</td>\n",
       "      <td>1.820978</td>\n",
       "      <td>0.919715</td>\n",
       "      <td>0.288723</td>\n",
       "      <td>-1.055973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.550201</td>\n",
       "      <td>-1.022922</td>\n",
       "      <td>-1.349817</td>\n",
       "      <td>0.118358</td>\n",
       "      <td>-0.403108</td>\n",
       "      <td>-0.137582</td>\n",
       "      <td>2.413711</td>\n",
       "      <td>1.906215</td>\n",
       "      <td>-0.712463</td>\n",
       "      <td>-0.393752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.270879</td>\n",
       "      <td>-0.687957</td>\n",
       "      <td>-1.654322</td>\n",
       "      <td>1.975529</td>\n",
       "      <td>-0.241883</td>\n",
       "      <td>-0.693959</td>\n",
       "      <td>1.812806</td>\n",
       "      <td>0.535059</td>\n",
       "      <td>0.363934</td>\n",
       "      <td>-1.347403</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.001279</td>\n",
       "      <td>1.729995</td>\n",
       "      <td>-1.380073</td>\n",
       "      <td>-1.755755</td>\n",
       "      <td>-0.174952</td>\n",
       "      <td>0.499850</td>\n",
       "      <td>2.632064</td>\n",
       "      <td>-0.730326</td>\n",
       "      <td>0.397858</td>\n",
       "      <td>-0.527553</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.504512</td>\n",
       "      <td>1.150465</td>\n",
       "      <td>1.167045</td>\n",
       "      <td>-0.650929</td>\n",
       "      <td>-0.398942</td>\n",
       "      <td>1.314107</td>\n",
       "      <td>2.139182</td>\n",
       "      <td>-0.561565</td>\n",
       "      <td>-1.747482</td>\n",
       "      <td>-0.853085</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_duration_ms  acousticness  danceability    energy  instrumentalness  \\\n",
       "0          1.270568     -1.147494      0.528199  0.350624         -0.321015   \n",
       "1          1.550201     -1.022922     -1.349817  0.118358         -0.403108   \n",
       "2          1.270879     -0.687957     -1.654322  1.975529         -0.241883   \n",
       "3         -1.001279      1.729995     -1.380073 -1.755755         -0.174952   \n",
       "4         -0.504512      1.150465      1.167045 -0.650929         -0.398942   \n",
       "\n",
       "   liveness  loudness  speechiness     tempo  audio_valence  ...  \\\n",
       "0  0.802553  1.820978     0.919715  0.288723      -1.055973  ...   \n",
       "1 -0.137582  2.413711     1.906215 -0.712463      -0.393752  ...   \n",
       "2 -0.693959  1.812806     0.535059  0.363934      -1.347403  ...   \n",
       "3  0.499850  2.632064    -0.730326  0.397858      -0.527553  ...   \n",
       "4  1.314107  2.139182    -0.561565 -1.747482      -0.853085  ...   \n",
       "\n",
       "   time_signature_3  time_signature_4  time_signature_5  \\\n",
       "0               0.0               1.0               0.0   \n",
       "1               0.0               1.0               0.0   \n",
       "2               1.0               0.0               0.0   \n",
       "3               1.0               0.0               0.0   \n",
       "4               1.0               0.0               0.0   \n",
       "\n",
       "   _song_duration_ms_imputed_  _acousticness_imputed_  _danceability_imputed_  \\\n",
       "0                         0.0                     0.0                     0.0   \n",
       "1                         0.0                     0.0                     0.0   \n",
       "2                         0.0                     1.0                     0.0   \n",
       "3                         0.0                     0.0                     0.0   \n",
       "4                         0.0                     0.0                     0.0   \n",
       "\n",
       "   _energy_imputed_  _instrumentalness_imputed_  _liveness_imputed_  \\\n",
       "0               1.0                         0.0                 0.0   \n",
       "1               0.0                         0.0                 0.0   \n",
       "2               0.0                         0.0                 0.0   \n",
       "3               0.0                         0.0                 0.0   \n",
       "4               1.0                         0.0                 0.0   \n",
       "\n",
       "   _loudness_imputed_  \n",
       "0                 1.0  \n",
       "1                 0.0  \n",
       "2                 1.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor_pipe.fit(X_train_full)\n",
    "X_preprocessed = preprocessor_pipe.transform(X_train_full)\n",
    "X_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom transformations for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descritizing `instrumentalness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# for modeling\n",
    "class Descretizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, descritizer, variable, inplace=False, **kwrgs):\n",
    "        self.variable = variable\n",
    "        self.inplace = inplace\n",
    "        self.descritizer = descritizer(**kwrgs)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.descritizer.fit(X[[self.variable]])\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.inplace:\n",
    "            X[self.variable] = self.descritizer.predict(X[[self.variable]])\n",
    "        else:\n",
    "            X[self.variable+\"_descrete\"] = self.descritizer.predict(X[[self.variable]])\n",
    "\n",
    "        if y is None:\n",
    "            return X\n",
    "        else:\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-031779e8-4ee2-4c6d-965b-0f06f869198b {color: black;background-color: white;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b pre{padding: 0;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-toggleable {background-color: white;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-estimator:hover {background-color: #d4ebff;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-item {z-index: 1;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-parallel-item:only-child::after {width: 0;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-031779e8-4ee2-4c6d-965b-0f06f869198b div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-031779e8-4ee2-4c6d-965b-0f06f869198b\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a2131081-211a-477b-bb1e-cbfb1c1da263\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a2131081-211a-477b-bb1e-cbfb1c1da263\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor_pipe',\n",
       "                 Pipeline(steps=[('na-imputation',\n",
       "                                  Imputer(imputer=IterativeImputer(add_indicator=True))),\n",
       "                                 ('transformation',\n",
       "                                  PreProcessorTransformer(cols=['acousticness',\n",
       "                                                                'danceability',\n",
       "                                                                'energy',\n",
       "                                                                'instrumentalness',\n",
       "                                                                'liveness',\n",
       "                                                                'speechiness',\n",
       "                                                                'audio_valence',\n",
       "                                                                'song_duration_ms',\n",
       "                                                                'tempo'])),\n",
       "                                 ('outlier remover',\n",
       "                                  OutlierRemover(outlier_remover=LocalOutlierFactor(contamination=0.02)))])),\n",
       "                ('descretizer_pipe',\n",
       "                 Descretizer(descritizer=KMeans(n_clusters=5, random_state=0),\n",
       "                             inplace=True, variable='instrumentalness'))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a1133503-b202-4448-b070-a28202318af9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a1133503-b202-4448-b070-a28202318af9\">preprocessor_pipe: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('na-imputation',\n",
       "                 Imputer(imputer=IterativeImputer(add_indicator=True))),\n",
       "                ('transformation',\n",
       "                 PreProcessorTransformer(cols=['acousticness', 'danceability',\n",
       "                                               'energy', 'instrumentalness',\n",
       "                                               'liveness', 'speechiness',\n",
       "                                               'audio_valence',\n",
       "                                               'song_duration_ms', 'tempo'])),\n",
       "                ('outlier remover',\n",
       "                 OutlierRemover(outlier_remover=LocalOutlierFactor(contamination=0.02)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8c8df190-544f-40a1-9f35-d8cefac350e9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8c8df190-544f-40a1-9f35-d8cefac350e9\">na-imputation: Imputer</label><div class=\"sk-toggleable__content\"><pre>Imputer(imputer=IterativeImputer(add_indicator=True))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a438813c-4971-4ba4-93da-4b22c8c30739\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a438813c-4971-4ba4-93da-4b22c8c30739\">IterativeImputer</label><div class=\"sk-toggleable__content\"><pre>IterativeImputer(add_indicator=True)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5db12d49-6b68-422d-bf78-a2d41eb25652\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5db12d49-6b68-422d-bf78-a2d41eb25652\">PreProcessorTransformer</label><div class=\"sk-toggleable__content\"><pre>PreProcessorTransformer(cols=['acousticness', 'danceability', 'energy',\n",
       "                              'instrumentalness', 'liveness', 'speechiness',\n",
       "                              'audio_valence', 'song_duration_ms', 'tempo'])</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"32de2ec8-15d0-4b7e-b101-afdd0e2a2ab8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"32de2ec8-15d0-4b7e-b101-afdd0e2a2ab8\">outlier remover: OutlierRemover</label><div class=\"sk-toggleable__content\"><pre>OutlierRemover(outlier_remover=LocalOutlierFactor(contamination=0.02))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3d049c7d-5527-4f62-a91c-54220b101ced\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3d049c7d-5527-4f62-a91c-54220b101ced\">LocalOutlierFactor</label><div class=\"sk-toggleable__content\"><pre>LocalOutlierFactor(contamination=0.02)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"853de926-af2c-4602-bc53-c643d2c82c07\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"853de926-af2c-4602-bc53-c643d2c82c07\">descretizer_pipe: Descretizer</label><div class=\"sk-toggleable__content\"><pre>Descretizer(descritizer=KMeans(n_clusters=5, random_state=0), inplace=True,\n",
       "            variable='instrumentalness')</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"84f286cc-4bd1-4f9b-adda-0b14be7e74c9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"84f286cc-4bd1-4f9b-adda-0b14be7e74c9\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=5, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor_pipe',\n",
       "                 Pipeline(steps=[('na-imputation',\n",
       "                                  Imputer(imputer=IterativeImputer(add_indicator=True))),\n",
       "                                 ('transformation',\n",
       "                                  PreProcessorTransformer(cols=['acousticness',\n",
       "                                                                'danceability',\n",
       "                                                                'energy',\n",
       "                                                                'instrumentalness',\n",
       "                                                                'liveness',\n",
       "                                                                'speechiness',\n",
       "                                                                'audio_valence',\n",
       "                                                                'song_duration_ms',\n",
       "                                                                'tempo'])),\n",
       "                                 ('outlier remover',\n",
       "                                  OutlierRemover(outlier_remover=LocalOutlierFactor(contamination=0.02)))])),\n",
       "                ('descretizer_pipe',\n",
       "                 Descretizer(descritizer=KMeans(n_clusters=5, random_state=0),\n",
       "                             inplace=True, variable='instrumentalness'))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descretizer = Descretizer(KMeans, 'instrumentalness', True, n_clusters=5, random_state=0)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor_pipe', preprocessor_pipe),\n",
    "    ('descretizer_pipe', descretizer),\n",
    "])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transform() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23012/377903055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train_preprocessed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_preprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_train_preprocessed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_preprocessed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: transform() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train_full, y_train_full)\n",
    "X_train_preprocessed, y_train_preprocessed = pipe.transform(X_train_full, y_train_full)\n",
    "X_train_preprocessed, y_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_pipe = Pipeline([\n",
    "    (\"na-imputation\", imputer),\n",
    "    (\"transformation\", transformer),\n",
    "])\n",
    "\n",
    "preprocessor_pipe.fit(X_train_full)\n",
    "X_preprocessed = preprocessor_pipe.transform(X_train_full)\n",
    "\n",
    "outlier_remover = OutlierRemover(LocalOutlierFactor, n_neighbors=20, contamination=0.02)\n",
    "outlier_remover.fit(X_preprocessed, y_train_full)\n",
    "X_train_preprocessed, y_train_preprocessed = outlier_remover.transform(X_preprocessed, y_train_full)\n",
    "\n",
    "descretizer = Descretizer(KMeans, 'instrumentalness', True, n_clusters=5, random_state=0)\n",
    "descretizer.fit(X_train_preprocessed)\n",
    "X_train_preprocessed = descretizer.transform(X_train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31360, 35), (31360,), (32000, 28), (32000,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed.shape, y_train_preprocessed.shape, X_train_full.shape, y_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "\n",
    "brute force through all models: the worst possible way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ml-model-selection\n",
      "  Downloading ml_model_selection-1.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from ml-model-selection) (1.21.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from ml-model-selection) (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from matplotlib->ml-model-selection) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from matplotlib->ml-model-selection) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from matplotlib->ml-model-selection) (8.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from matplotlib->ml-model-selection) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from matplotlib->ml-model-selection) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from cycler>=0.10->matplotlib->ml-model-selection) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from sklearn->ml-model-selection) (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from scikit-learn->sklearn->ml-model-selection) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from scikit-learn->sklearn->ml-model-selection) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\akshu\\.conda\\envs\\ml\\lib\\site-packages (from scikit-learn->sklearn->ml-model-selection) (2.2.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=7bc0941884cc755cd76ad36ce70d04be86460bc1179dbe896f047589e64e9ef9\n",
      "  Stored in directory: c:\\users\\akshu\\appdata\\local\\pip\\cache\\wheels\\e4\\7b\\98\\b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn, ml-model-selection\n",
      "Successfully installed ml-model-selection-1.0.0 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install lazypredict\n",
    "# !pip install ml-model-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_selection import models_validation\n",
    "\n",
    "model_paramGrid_list = [\n",
    "                            (\"NB\", GaussianNB(), {}),\n",
    "                            (\"LR\", LogisticRegression(), {\"penalty\" : [\"l1\", \"l2\"],\n",
    "                                                            \"C\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                            \"solver\" : [\"liblinear\", \"saga\"]}),\n",
    "                            (\"RidgeClassifier\", RidgeClassifier(), {\"alpha\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                    \"solver\" : [\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]}),\n",
    "                            (\"RidgeClassifierCV\", RidgeClassifierCV(), {\"alphas\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                        \"cv\" : [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                                                                        \"solver\" : [\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]}),\n",
    "                            (\"Lasso\", Lasso(), {\"alpha\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                \"solver\" : [\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]}),\n",
    "                            (\"LassoCV\", LassoCV(), {\"alphas\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                    \"cv\" : [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                                                    \"solver\" : [\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]}),\n",
    "                            (\"ElasticNet\", ElasticNet(), {\"alpha\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                            \"l1_ratio\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                            \"solver\" : [\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]}),\n",
    "                            (\"ElasticNetCV\", ElasticNetCV(), {\"alphas\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"l1_ratio\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"cv\" : [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                                                                \"solver\" : [\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]}),\n",
    "                            (\"LogisticRegressionCV\", LogisticRegressionCV(), {\"penalty\" : [\"l1\", \"l2\"],\n",
    "                                                                                \"C\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                                \"cv\" : [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                                                                                \"solver\" : [\"liblinear\", \"saga\"]}),\n",
    "                            (\"SGDClassifier\", SGDClassifier(), {\"loss\" : [\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"],\n",
    "                                                                \"penalty\" : [\"l2\", \"l1\", \"elasticnet\"],\n",
    "                                                                \"alpha\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"l1_ratio\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"fit_intercept\" : [True, False],\n",
    "                                                                \"max_iter\" : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "                                                                \"tol\" : [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                                                                \"shuffle\" : [True, False],\n",
    "                                                                \"verbose\" : [True, False],\n",
    "                                                                \"epsilon\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"n_jobs\" : [-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                                                \"warm_start\" : [True, False],\n",
    "                                                                \"average\" : [True, False],\n",
    "                                                                \"class_weight\" : [\"balanced\", None]}),\n",
    "                            (\"SGDRegressor\", SGDRegressor(), {\"loss\" : [\"squared_loss\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"],\n",
    "                                                                \"penalty\" : [\"l2\", \"l1\", \"elasticnet\"],\n",
    "                                                                \"alpha\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"l1_ratio\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"fit_intercept\" : [True, False],\n",
    "                                                                \"max_iter\" : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "                                                                \"tol\" : [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                                                                \"shuffle\" : [True, False],\n",
    "                                                                \"verbose\" : [True, False],\n",
    "                                                                \"epsilon\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"n_jobs\" : [-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                                                \"warm_start\" : [True, False],\n",
    "                                                                \"average\" : [True, False],\n",
    "                                                                \"class_weight\" : [\"balanced\", None]}),\n",
    "                            (\"Ridge\", Ridge(), {\"alpha\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                \"fit_intercept\" : [True, False],\n",
    "                                                \"normalize\" : [True, False],\n",
    "                                                \"solver\" : [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]}),\n",
    "                            (\"RidgeCV\", RidgeCV(), {\"alphas\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                    \"fit_intercept\" : [True, False],\n",
    "                                                    \"normalize\" : [True, False],\n",
    "                                                    \"cv\" : [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                                                    \"solver\" : [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]}),\n",
    "                            (\"Lasso\", Lasso(), {\"alpha\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                \"fit_intercept\" : [True, False],\n",
    "                                                \"normalize\" : [True, False],\n",
    "                                                \"precompute\" : [True, False],\n",
    "                                                \"max_iter\" : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "                                                \"tol\" : [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                                                \"copy_X\" : [True, False],\n",
    "                                                \"warm_start\" : [True, False],\n",
    "                                                \"positive\" : [True, False],\n",
    "                                                \"random_state\" : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}),\n",
    "                            (\"LassoCV\", LassoCV(), {\"alphas\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                    \"fit_intercept\" : [True, False],\n",
    "                                                    \"normalize\" : [True, False],\n",
    "                                                    \"precompute\" : [True, False],\n",
    "                                                    \"max_iter\" : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "                                                    \"tol\" : [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                                                    \"copy_X\" : [True, False],\n",
    "                                                    \"warm_start\" : [True, False],\n",
    "                                                    \"positive\" : [True, False],\n",
    "                                                    \"random_state\" : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                                    \"cv\" : [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]}),\n",
    "                            (\"LassoLars\", LassoLars(), {\"alpha\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                        \"fit_intercept\" : [True, False],\n",
    "                                                        \"normalize\" : [True, False],\n",
    "                                                        \"precompute\" : [True, False],\n",
    "                                                        \"max_iter\" : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "                                                        \"tol\" : [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                                                        \"copy_X\" : [True, False],\n",
    "                                                        \"warm_start\" : [True, False],\n",
    "                                                        \"positive\" : [True, False],\n",
    "                                                        \"random_state\" : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}),\n",
    "                            (\"LassoLarsCV\", LassoLarsCV(), {\"alphas\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                            \"fit_intercept\" : [True, False],\n",
    "                                                            \"normalize\" : [True, False],\n",
    "                                                            \"precompute\" : [True, False],\n",
    "                                                            \"max_iter\" : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "                                                            \"tol\" : [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                                                            \"copy_X\" : [True, False],\n",
    "                                                            \"warm_start\" : [True, False],\n",
    "                                                            \"positive\" : [True, False],\n",
    "                                                            \"random_state\" : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                                            \"cv\" : [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]}),\n",
    "                            (\"BayesianRidge\", BayesianRidge(), {\"n_iter\" : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "                                                                \"tol\" : [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                                                                \"alpha_1\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"alpha_2\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"lambda_1\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"lambda_2\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                \"fit_intercept\" : [True, False],\n",
    "                                                                \"normalize\" : [True, False],\n",
    "                                                                \"copy_X\" : [True, False],\n",
    "                                                                \"verbose\" : [True, False],\n",
    "                                                                \"n_jobs\" : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}),                       \n",
    "                            (\"SVC\", SVC(), {\"kernel\" : [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                                            \"C\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                            \"gamma\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}),\n",
    "                            (\"NuSVC\", NuSVC(), {\"kernel\" : [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                                                \"nu\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                \"gamma\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}),\n",
    "                                                \n",
    "                            (\"KNN\", KNeighborsClassifier(), {\"n_neighbors\" : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                                                \"weights\" : [\"uniform\", \"distance\"],\n",
    "                                                                \"algorithm\" : [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                                                                \"p\" : [1, 2, 3]}),\n",
    "                            (\"DT\", DecisionTreeClassifier(), {\"criterion\" : [\"gini\", \"entropy\"],\n",
    "                                                                \"max_depth\" : [None, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                    \"min_samples_split\" : [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                    \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                    \"max_features\" : [None, \"auto\", \"sqrt\", \"log2\"]}),\n",
    "                            (\"RF\", RandomForestClassifier(), {\"n_estimators\" : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                                                                \"criterion\" : [\"gini\", \"entropy\"],\n",
    "                                                                \"max_depth\" : [None, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                \"min_samples_split\" : [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                \"max_features\" : [None, \"auto\", \"sqrt\", \"log2\"]}),\n",
    "                            (\"ETC\", ExtraTreeClassifier(), {\"n_estimators\" : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                                                                \"criterion\" : [\"gini\", \"entropy\"],\n",
    "                                                                \"max_depth\" : [None, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                \"min_samples_split\" : [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                \"max_features\" : [None, \"auto\", \"sqrt\", \"log2\"]}),\n",
    "                            (\"GB\", GradientBoostingClassifier(), {\"n_estimators\" : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                                                                    \"learning_rate\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                                    \"max_depth\" : [None, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                    \"min_samples_split\" : [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                    \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                                                                    \"max_features\" : [None, \"auto\", \"sqrt\", \"log2\"]}),\n",
    "                            (\"AB\", AdaBoostClassifier(), {\"n_estimators\" : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                                                            \"learning_rate\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}),\n",
    "                            (\"VotingClassifier\", VotingClassifier(\n",
    "                                estimators=[('rf', RandomForestClassifier()), \n",
    "                                            ('lr', LogisticRegression()), \n",
    "                                            ('svm', SVC()), \n",
    "                                            ('dt', DecisionTreeClassifier()),\n",
    "                                            ('knn', KNeighborsClassifier()),\n",
    "                                            ('nb', GaussianNB()),\n",
    "                                            ('et', ExtraTreesClassifier()),\n",
    "                                            ('gb', GradientBoostingClassifier()),\n",
    "                                            ('ab', AdaBoostClassifier())],\n",
    "                                voting='soft'), {}),\n",
    "                            (\"BaggingClassifier\", BaggingClassifier(), {\"bese_estimator\" : [RandomForestClassifier(),\n",
    "                                                                                                LogisticRegression(),\n",
    "                                                                                                SVC(),\n",
    "                                                                                                DecisionTreeClassifier(),\n",
    "                                                                                                KNeighborsClassifier(),\n",
    "                                                                                                GaussianNB(),\n",
    "                                                                                                ExtraTreesClassifier(),\n",
    "                                                                                                GradientBoostingClassifier(),\n",
    "                                                                                                AdaBoostClassifier()]}),\n",
    "                            (\"StackingClassifier\", StackingClassifier(\n",
    "                                estimators=[('rf', RandomForestClassifier()),\n",
    "                                            ('lr', LogisticRegression()),\n",
    "                                            ('svm', SVC()),\n",
    "                                            ('dt', DecisionTreeClassifier()),\n",
    "                                            ('knn', KNeighborsClassifier()),\n",
    "                                            ('nb', GaussianNB()),\n",
    "                                            ('et', ExtraTreesClassifier()),\n",
    "                                            ('gb', GradientBoostingClassifier()),\n",
    "                                            ('ab', AdaBoostClassifier())]), {}),\n",
    "                                            \n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_train_val_score, models_best_params, best_index, test_score, ax = models_validation(X_train_preprocessed, y_train_preprocessed,\n",
    "                                                                                     model_paramGrid_list,\n",
    "                                                                                     plot=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a43319817bbc639f2299510b5445ad447bf1e0c8ec9e6531fb6bcc2536c660b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
